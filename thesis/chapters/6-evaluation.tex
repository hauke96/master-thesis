% !TEX root = ../thesis.tex
% !TeX spellcheck = en_US

The implementation of the hybrid routing algorithm was evaluated regarding performance and usefulness, which is covered in this chapter.
For both evaluation aspects, method and design details are given followed by the respective results of the evaluations.

\section{Performance evaluation}

	The performance evaluation uses different datasets to measure graph generation and routing times.
	Each of these two steps is measured more fine-grained by measuring the execution times of separate method calls.
	The datasets have different properties and sizes and consist of artificial and real-world data.

	\subsection{Methods \& Measurements}

		\subsubsection{Collected data}
		
			The collected data consists of time measurement, many of them on the level of separate methods.
			Also, the amount of data is measures, namely the number of edges and vertices at various steps in the process.
			
			As a result, two CSV files are written per dataset containing measurement data for the import (including graph generation) and routing.
			The measurement for the routing requests also contains information about the lengths of the routes, especially beeline and actual route distances.
			
			% TODO table with all columns of the measured data including a description and example value?
		
		\subsubsection{Datasets}
		
			There are multiple categories of datasets that were used.
			Pattern-based datasets are created using a pattern, e.g. a set of rectangles, repeated numerous times to create datasets of various sizes.
			OSM-based datasets use differently sized extracts from OpenStreetMap.
			While the OSM-based datasets contain obstacles and roads (except in the \enquote{without roads/obstacles} datasets), the pattern-based datasets do no contain any roads.
			
			\begin{description}
				\item[Maze pattern] Datasets of this category are made of maze like geometries, meaning it only contains connected linestrings forming a seamless pattern. Many of the contained line obstacles are collinear.
				\item[Rectangle pattern] Pattern-based datasets, which contain simple rectangles of different sizes.
				\item[Circle pattern] Like the rectangle datasets but with circles, i.e. polygons with a large number of vertices.
				\item[OSM city] Real-world extracts from the OpenStreetMap database with data from the city of Hamburg, Germany. The data has been filtered to remove all over- and underground features. These datasets contain all roads in the respective region.
				\item[OSM rural] Equivalent to the \enquote{OSM city} dataset, but located outside the city of Hamburg and therefore containing more natural obstacles (lakes, ditches, forest), more open spaces and less regular distribution of buildings.
				\item[OSM export without roads] OSM extracts but without the roads. They are used to show the influence of roads on the graph generation and routing times.
				\item[OSM export without obstacles] Analogous to the \enquote{OSM export without roads} category, but without the obstacles, i.e. buildings, walls and natural areas such as lakes and forests. This is used to show the influence of the obstacles on the graph generation and routing times.
			\end{description}
			The \enquote{OSM city} and \enquote{OSM rural} categories each contain six dataset of the sizes 0.5, 1, 1.5, 2, 3 and 4 km\textsuperscript{2}.
			The two OSM categories \enquote{without roads/obstacles} both use the 4 km\textsuperscript{2} datasets from the city and rural categories.
			
			\todo{Illustrate this as a diagram or list? Also list the number of raw vertices within the datasets.}
			
			\todo{List sizes/statistics of datasets?}
		
		\subsubsection{Optimizations}
		
			As described in \Cref{chap:implementation}, there were several optimizations made to the implementation.
			Some of which are on the level of data structures, some on algorithmic level.
			The effectiveness of these optimization was also evaluated using the OSM dataset.
			Each of the following optimizations was deactivated or replaced for the evaluation:

			\begin{description}
				\item[Shadow areas] Instead, every visibility check was performed using the custom intersection check described in \Cref{subsubsec:intersection-checks}.
				\item[Custom intersection check] The custom intersection check was replaced by the \todo[inline]{probably \texttt{RobustLineIntersector}?} class from the NTS to determine intersections between line segments.
				\item[BinIndex] Instead, the \texttt{BinTree} from the NTS was used.
				\item[Convex hull] The restriction to only consider vertices on the convex hull of obstacles was removed.
				\item[Valid angle areas] Considering only potential visibility neighbors within certain angular ranges was deactivated.
				\item[$k$-NN search] The $k$ of the k-NN search was deactivated to determine all visibility neighbors in all directions.
			\end{description}		
			
		\subsubsection{Measurement method}
		
			Measuring the performance was done by a small agent-based simulation project called \texttt{HikerModel}, which consists of one agent, a list of coordinates and the input dataset.
			The coordinates are given via a linestring within a GeoJSON file and each coordinate in this linestring is visited by the agent using the hybrid routing algorithm to determine the path from one location the the next.
%			The time of the graph generation as well as the time of each routing request are measured.
			Each waypoint was within the range of the dataset, meaning each coordinate was surrounded by obstacles.
			The euclidean distances (beeline distances) of the line segments within this linestring were distributed evenly to measure the required routing time relative to the distance and dataset size.
			
			Because the OSM datasets within one category cover differently sized areas, each waypoint linestring of a dataset contains all waypoints of the next smaller one plus some additional ones.
			This the waypoints of the smallest dataset are used by every other dataset as well.
%			In other words, the second smallest dataset contains all waypoints of the smallest plus some additional ones.
%			The third smallest contains all waypoints of the second smallest plus some additional ones, and so on.
		
		\subsubsection{Technical considerations}
		
			The measurement was done by a helper class \texttt{PerformanceMeasurement} providing a method accepting a function delegate which execution time is then measured.
			
			As part of its memory management, C\#/.NET uses automatic garbage collection adding unavoidable noise to the measurements.
			Unfortunately the garbage collector cannot be turned off and controling it is only partially possible.
		
			C\#/.NET also uses just-in-time (JIT) compilation changing the code during runtime.
			This can also not be turned off for normal .NET executions via the command \texttt{dotnet program.dll}.
			An alternative would be the usage of ahead-of-time (AOT) compilation, which has a negative impact on the performance of LINQ operations\footnote{According to \url{https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/?tabs=net7}}, which in turn are used very often in the implementation.
			Because both compilation strategies have disadvantages, the normal .NET-based execution was chosen, even though it contains JIT compilation.
			
			To mitigate this dynamic behavior and to generally get resilient results, the import and each routing request was performes multiple times.
			Precisely, three warm-up iterations were performed before measuring the times of five actual execution iterations.
			The execution times from the warm-up iterations indicated that three warm-up iterations were enough for the runtime to perform the JIT compilation and prepare the garbage collector.
			
			Additionally, the garbage collector was triggered during each of the eight iterations just before calling the measured function with the goal to provide equal circumstances to all iterations.
			This was done by the \texttt{GC.Collect()} and \texttt{GC.WaitForPendingFinalizers()} methods from the \texttt{GC} class of the .NET framework.
			Using these two methods forces a garbage collection and waits for it to finish\cite{ms-gc}.
			
			To prevent the garbage collection from interfering with the execution, a 256 MiB large no-GC-region is placed around the function call via \texttt{GC.TryStartNoGCRegion(256 * 1024 * 1024)}.
			This only works if enough memory is available\cite{ms-no-gc-region}, which was the case, and introducing this no-GC-region reduced the variance of the measured times.
			\todo[inline]{\enquote{reduced the variance of the measured times} \textrightarrow\ measure/test this?}
			
			Another step to get stable and reproducable results was the increase of the process priority.
			This aims to the exclusive use of one CPU core on which this single threaded application ran.
			Increasing the process priority was done by settings the \texttt{PriorityClass} property of the current process to \texttt{ProcessPriorityClass.High}, which required root permissions on Linux systems.
		
		\subsubsection{System and hardware}
		
			The measurements were performed on an up-to-date Arch Linux operating system (Kernel 6.3.9) with .NET Core 7.0.107 and MARS framework 4.5.2.
			Apart from necessary operating system processes and the simple desktop environment i3, no other applications ran during the performance measurements.
			
			The hardware consisted of an octa core Intel\textregistered\ Xeon\textregistered\ E3-1231 v3 CPU at 3.40 GHz, a total of 16GB DDR3 1333 MHz RAM and a Samsung EVO 850 SSD.
			However, the whole algorithm and the \texttt{HikerModel} simulation is single threaded.
			File system operations are only performed to initially load the input data and to write the results after performaing all measurements.
	
\section{Performance evaluation}

	In this section the results of the performance evaluation of the algorithm are presented.
	First the OSM-based datasets are discussed followed by the artificial pattern-based datasets.

	\subsection{OSM-based datasets}
		
		\subsubsection{Import and graph generation}
		
			As mentioned at the beginning of \Cref{subsec:related-work:visibility-graph}, the process of generating a visibility graph has an inherent quadratic runtime.
			This result is clearly visible in measurements of the dataset imports as seen in \Cref{fig:eval-import-city-abs} and \Cref{fig:eval-import-rural-abs}.
			
			\begin{figure}[h!]
				\begin{minipage}{.48\textwidth}
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-import-time-per-vertices.py_absolute.pgf}
						\end{figcenter}
						\caption{Absolute total graph generation time for the \enquote{OSM city} dataset.}
						\label{fig:eval-import-city-abs}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-import-time-per-vertices.py_per-vertex.pgf}
						\end{figcenter}
						\caption{Time per input vertex for the \enquote{OSM city} dataset.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-import-time-per-vertices.py_per-vertex-added.pgf}
						\end{figcenter}
						\caption{Increase in processing time per vertex when an additional vertex is added.}
						\label{fig:eval-import-city-rel-increase}
					\end{subfigure}
					\caption{Graph generation times using the \enquote{OSM city} dataset.}
					\label{fig:eval-import-city}
				\end{minipage}
				\hfill
				\begin{minipage}{.48\textwidth}
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-import-time-per-vertices.py_absolute.pgf}
						\end{figcenter}
						\caption{Absolute total graph generation time for the \enquote{OSM rural} dataset.}
						\label{fig:eval-import-rural-abs}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-import-time-per-vertices.py_per-vertex.pgf}
						\end{figcenter}
						\caption{Time per input vertex for the \enquote{OSM rural} dataset.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\linewidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-import-time-per-vertices.py_per-vertex-added.pgf}
							% TODO same y-scale in both figures
						\end{figcenter}
						\caption{Increase in processing time per vertex when an additional vertex is added.}
						\label{fig:eval-import-rural-rel-increase}
					\end{subfigure}
					\caption{Graph generation times using the \enquote{OSM rural} dataset.}
					\label{fig:eval-import-rural}
				\end{minipage}
			\end{figure}
			
			A few aspects regarding the runtime behavior can already be inferred from \Cref{fig:eval-import-city} and \Cref{fig:eval-import-rural}.
			
			First, as mentioned above, the inherent quadratic runtime of the visibility graph creation, which is shown in detail in the following \Cref{fig:eval-import-details}.
			
			Second, the linear increase in the processing time per vertex, which shows, that the total runtime is in fact quadratic and not, for example, exponential.
			
			And third, the additional effort added to each vertex when a new additional vertex is added to the dataset is very small (below one microsecond) and decreases with the size of the dataset.
			Taking the largest dataset of about 88.000 vertices in \Cref{fig:eval-import-city-rel-increase} as an example, adding one new vertex increases the processing time of every vertex by around 0.12 Âµs.
			At least for smaller datasets, as \Cref{fig:eval-import-rural-rel-increase} shows, this extra time for each additional vertex decreases with the size of the dataset.
			This indicates a slower growing processing time for larger datasets, however, this effect is negligible as it is not directly visible by the measured data in figures \ref{fig:eval-import-city-abs} and \ref{fig:eval-import-rural-abs}.
			
			\begin{figure}[h!]
				\begin{figcenter}
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-import-details-per-vertices.py_absolute.pgf}
						\end{figcenter}
						\caption{Import time of the \enquote{OSM city} dataset by tasks.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-import-details-per-vertices.py_absolute.pgf}
						\end{figcenter}
						\caption{Import time of the \enquote{OSM rural} dataset by tasks.}
					\end{subfigure}
				\end{figcenter}
				\caption{Details of graph generation times for the two datasets \enquote{OSM city} (above) and \enquote{OSM rural} (below).}
				\label{fig:eval-import-details}
			\end{figure}
			
			In \Cref{fig:eval-import-details} both OSM dataset import times are split into the performed tasks.
			The task with the largest effort in terms of the required time is the $k$ nearest neighbor (kNN) search.
			This step takes, even for the smallest dataset, at least 50\% of the overall hybrid visibility graph generation time.
			For the largest dataset in the \enquote{OSM city} set, the share of the kNN search on the total processing time was over 97\%.
			The second most time consuming step is the merge of the road network with the visibility graph which has a share of not more than 3.5\% in any of the \enquote{OSM city} datasets.
			All other steps have a negligible effect on the processing performance with a combined share of less than 0.8\% on the total processing time of the \enquote{OSM city} dataset.
			
			Very small datasets, meaning only a few thousand vertices, show a different distribution.
			Even though the kNN search is still the most expensive task, the relative shares of other tasks, especially the marge operation, are significantly higher.
			\todo[inline]{reasons for this}
			
			\todo{Table with values? Absolute or relative?}
	
		\subsubsection{Routing}
		
			The time required for routing is influences by several different factors.
			First of all, routing consists of several tasks, each contributing to the overall routing time by different proportions.
			Second, the dataset size is a strong influencing factor but has differently strong influence on the several routing tasks.
			Third, the structure of the data, meaning the number, size and distribution of obstacles, also influences the required time for routing.
			In fact, the size of the dataset is the strongest influence on the overall routing time as it affects all tasks during routing.
		
			\clearpage
			\begin{figure}[h!]
				\begin{figcenter}
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-routing-time.py_distance.pgf}
						\end{figcenter}
						\caption{Total routing times of all datasets.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-routing-time-details.py_absolute_45018.pgf}
						\end{figcenter}
						\caption{Each task during routing of the largest dataset with 45018 input vertices.}
						\label{fig:eval-city-routing-details-b}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-routing-time-details.py_relative_45018.pgf}
						\end{figcenter}
						\caption{Same as \Cref{fig:eval-city-routing-details-b} but showing the relative shares on the total time.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-city/plot-routing-time-details.py_absolute_all.pgf}
						\end{figcenter}
						\caption{Routing between the same waypoints appearing in all datasets (distance between the waypoints: 600 m).}
					\end{subfigure}
				\end{figcenter}
				\caption{Routing time statistics of the \enquote{OSM city} datasets.}
			\end{figure}
			
			\clearpage
			\begin{figure}[h!]
				\begin{figcenter}
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-routing-time.py_distance.pgf}
						\end{figcenter}
						\caption{Total routing times of all datasets.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-routing-time-details.py_absolute_06055.pgf}
						\end{figcenter}
						\caption{Detailed routing times of the largest dataset with 6055 input vertices.}
						\label{fig:eval-rural-routing-details-b}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-routing-time-details.py_relative_06055.pgf}
						\end{figcenter}
						\caption{Same as \Cref{fig:eval-rural-routing-details-b} but showing the relative shares on the total time.}
					\end{subfigure}
					\\[3ex]
					\begin{subfigure}[t]{\textwidth}
						\begin{figcenter}
							\input{images/evaluation/osm-based-rural/plot-routing-time-details.py_absolute_all.pgf}
						\end{figcenter}
						\caption{Routing between the same waypoints appearing in all datasets (distance between the waypoints: 600 m).}
					\end{subfigure}
				\end{figcenter}
				\caption{Routing time statistics of the \enquote{OSM rural} datasets.}
			\end{figure}
			
			\todo{Why is the rural-routing slower for shorter distances? And what happened at the jump between 1.0 and 1.5km? -- Slower queries have waypoints on open field = few shadow areas = lots of checks. Faster queries have waypoints near obstacles = better usage of shadow areas}
		
		\todo{Detailed view (as above)}
		
		\todo{Times per meter?}
	
\section{Route correctness and quality}

	\subsection{Correctness}
	
		% is the shortest route really the shortest
		The hybrid routing algorithm is considered \emph{correct} if the resulting path between any two given locations is the shortest possible path with respect to the obstacled of the dataset.
		Edges on a visibility graph, which was constructed using vertices from obstacles in the plain, represents shortest segments between vertices of obstacles.
		In other words, for any two vertices $v$ and $v'$, the edge $e$ from the visibility graph is the shortest possible connection between these two vertices without intersecting with any obstacle.
		A shortest path through a visibility graph is therefore equal to a shortest geometric path around obstacles in the plain.
		
		For shortest paths algorithms, such as A* or Dijkstra, the term \emph{correct} refers to the fact that their result is the shortest possible path between two vertices in a graph.
		The correctness of the hybrid routing algorithm presented in this thesis is identical to this and follows from the argumentation above.
		
		In addition to routing on a visibility graph, the presented hybrid routing algorithm actively connects locations to the graph as part of answering the routing query yielding a temporarily augmented graph.
		This means the resulting path $p$ from vertex $s$ to $t$ contains two additional edges $(s, v_s)$ and $(v_t, t)$, which are not part of the normal hybrid visibility graph, resulting in $p=\left\langle s, v_s, ..., v_t, t \right\rangle$.
		These two additional edges are visibility edges and the correctness argument applies to them as well, meaning that the overall path $p$ is shortest on the augmented visibility graph and therefore shortest in the geometric domain of obstacles in the plain.
		
		Two aspects are noteworthy in the context of correctness.
		
		First, the A* implementation of MARS accepts other weight functions than the default \enquote{shortest}-function.
		This is also possible in the hybrid routing algorith when calling the \texttt{OptimalPath} method, which accepts a \texttt{Func} delegate as weight function.
		
		Second, filtering the potential visibility neighbors as described in \Cref{subsec:step-2-knn-search} might result in missing edges.
		This has a direct effect on the quality of the resulting paths since they may not be optimal anymore.
		\todo[inline]{Determine: Number of edges missing vs. performance boost}
		
	\subsection{Usefulness of routes}
	
		% How realistic are the routes (= can I go there in real life)? If not: Why not?
		% How much shorter are the routes?