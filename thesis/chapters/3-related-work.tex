% !TeX root = ../thesis.tex
% !TeX spellcheck = en_US

In this chapter, an overview of scientific literature from the areas of graph construction, routing and (pedestrian) path planning is given.

\section{Graph generation}
\label{sec:graph-generation}

	Generating edges to create a graph is an essential topic in this thesis.
	However, enhancing and filling existing graphs is closely related and use similar or the same mechanisms.
	Numerous approaches exist and have been used and discussed in the literature.
	This section gives an overview of some approaches.

	\subsection{Visibility graphs}
	\label{subsec:related-work:visibility-graph}

		Constructing a visibility graph is a central part of this thesis.
		Even though numerous approaches to creating such graphs have been presented over the last decades, the worst-case time complexity of this problem will always be quadratic.
		This is due to the worst-case graph where all $n$ vertices are visible to each other (complete graph), creating $\Omega(n^2)$ edges in the output graph (precisely $\frac{n^2-n}{n}$, which is the highest possible number of edges in a graph).
		
		The construction of visibility graphs in $\bigo{n^2}$ time and space (with $n$ line segments), under the condition of no collinear vertices and no intersecting line segments, was presented by Welzl in 1985\cite{welzl-visibility-graph}.
		
		A few years later, in 1988, Overmars and Welzl presented two new methods reducing the space complexity to $\bigo{n}$\cite{overmars-weizl-visibility-graph} and one of these methods has a time complexity of $\bigo{E \log n}$ with $E$ being the number of output edges.
		Their new algorithms are based on Welzl's earlier paper and implement the idea of a rotational sweep through neighboring vertices.
		
		The time complexity of Overmars' and Welzl's approach is output-sensitive with respect to the number of edges in the output graph\cite{ghosh-output-sensitive-vgraph}.
		Ghosh and Mount presented an algorithm with an output-sensitive complexity of $\bigo{E + n \log n}$, which is a significant improvement since $E$ is in $\bigo{n^2}$.
		However, their approach needs $\bigo{E + n}$ space compared to $\bigo{n}$ from the algorithms by Overmars and Welzl.
		Ghosh and Mount use plane-sweeps to create a triangulation of the free space and introduced so-called \emph{funnel sequences}, which are sets of vertices visible to parts of an edge.
		To avoid numerous edge cases, their approach assumes no collinear vertices and unique x-coordinates.
		
		Kapoor and Maheshwari introduced two algorithms, one for determining shortest paths and one for creating a visibility graph, which are both based on triangulations as well\cite{kapoor-shortest-path-vgraph}.
		With their approach, finding shortest paths in the presence of $m$ polygonal obstacles works in $\bigo{m^2 \log{n} + n\log{n}}$, but only uses a certain subset of the visibility graph to actually determine the shortest path.
		Their visibility graph creation is done in $\bigo{E+T}$, with $T$ being the time needed to triangulate the space between the obstacles, and therefore has the same complexity as Ghosh and Mounts algorithm since a triangulation of the space between $n$ obstacles can be done in $\bigo{N \log{N}}$\cite{tereshchenko-triangulating-open-spaces}, where $N$ is the number of vertices.
		Due to its simpler structure, the approach by Kapoor and Maheshwari might lead to a better performance in practice.

		Krisp et al. also implemented a visibility graph-based routing algorithm and, more interesting in this case, measured its performance\cite{krisp-goal-directed-routing}:
		It took over 9.5 hours to determine a path through a city quarter.
		One must mention, that the paper was published in 2010 and the speed of computers has increased since then.
		Also, it is unknown how well optimized their implementation was.
		Nonetheless, this time gives an indication of the computational complexity of creating a visibility graph.
	
	\subsection{Enhancing existing graphs}
	
		Graph generation techniques can be used to add missing edges to routing graphs or to enhance these in case of a low degree of detail.
		
		Funke et al. achieved this by filling holes in an existing road graph, which was the OpenStreetMap network in their case\cite{funke-osm-extrapolation}.
		To do so, they developed a metric to detect holes in an existing graph based on the following idea:
		If the shortest path between two vertices is much longer than the Euclidean distance, the network probably has a hole.
		However, this metric produces false positive results when large obstacles, such as rivers, are between the two vertices.
		In this case, the Euclidean and shortest path distances significantly differ, which is indeed correct in such cases.
		To handle these problems caused by large obstacles, they discussed the use of Mitchell's implementation of the \hyperref[subsec:continuous-dijkstra]{continuous Dijkstra paradigm} as presented in \Cref{related-work:mitchell}.
		Due to the complexity and lower performance, they decided to use a dense grid instead, cutting out edges intersecting obstacles and use this remaining grid for navigation.
		Unfortunately, the use of other graph generation algorithms (for example visibility graph construction) was not discussed.
		
		Andreev et al. also worked on the existing OpenStreetMap graph and added sidewalks to roads for more realistic routing and also tried to handle arbitrary source and destination locations of routing queries\cite{andreev-osm-generate-sidewalks}.
		They not only added sidewalks but also dealt with open spaces such as plazas and parks.
		For each plaza, which usually does not contain designated footways, they create a visibility graph to generate edges within the plaza.
		Edges not relevant for paths through the plaza are removed afterward.
		Parks are handled differently since they often contain designated paths.
		If the source or destination starts within a park, special edges are added based on the walking speed and existing edges for paths within the park.
		After this preprocessing, Dijkstra is used to determine the complete shortest path.
	
	\subsection{Filling open spaces}
	\label{subsec:filling-open-spaces}
	
		A task, which is more relevant for this thesis, is filling open spaces with edges for navigation purposes.
		This can be done by using one of several approaches.
	
		Kneidl, Borrmann and Hartmann used visibility graphs to produce a sparse graph suitable for navigation\cite{kneidl-borrmann-hartmann-navigation}.
		They chose to construct a visibility graph rather than generalized Voronoi diagrams for more realistic edges.
		
		Liu and Zlatanova used the same strategy for indoor routing through open spaces\cite{liu-indoor-routing}, however, they took the spatial size of pedestrians into account and added a buffer area around obstacles to prevent pedestrians from intersecting with obstacles.
		Xu et al. also created a precise indoor navigation algorithm, but they used a certain Delaunay triangulation, which is faster than the visibility graph creation and still creates paths of sufficient quality\cite{xu-indoor-delaunay}.
		
		Another interesting paper on enhancing existing navigation graphs was presented in 2016 by Anita Graser, where she integrated visibility graph edges into the existing OSM data model\cite{graser-osm-open-spaces}.
		Again, the visibility graph was the preferred method to generate edges.
		Considered and discussed alternatives were two skeletonization methods and the usage of a simple grid filling the open spaces.
		
	\subsection{Generate graphs from existing maps}
	\label{subsection:generate-graphs-from-maps}
	
		A graph is not always available, which motivated Walter et al. to create a procedure using raster maps\cite{walter-raster-maps}.
		They proposed an algorithm with four steps:
		First, the raster data is classified in obstacle and non-obstacle pixels.
		Second, the data is used to create a skeletonization graph from it.
		Third, this graph is used for routing with the A* algorithm.
		Fourth, the result is smoothed since the skeletonization might yield edges that pedestrians will not naturally use.
		Even though this technique works well on large datasets, the reason for choosing skeletonization instead of visibility edges or other generation algorithms was not further discussed.
		
		A similar work was presented by Birgit Elias, merging multiple data sources, like topographical maps or indoor building plans, into one vector dataset for routing\cite{elias-tailored-geodatabase}.
		To create a graph from existing maps, she used a skeletonization method based on a Delaunay triangulation.
		She also considered that important point-like structures, like entrances or other points of interest, must also be connected to the graph.
		This was solved by creating a perpendicular line to the nearest edge of the graph.
		The problem of unconnected points of interest is one topic of this thesis and is solved during graph creation as mentioned later in \Cref{subsec:step-1-preprocessing}.
		
	\subsection{Crowd sourced graph generation}
	
		All graph generation methods presented so far are algorithmic approaches.
		However, mobile devices can store the user's location and trajectory, which can be used as a data source to construct a navigation graph.
		
		Kasemsuppakorn et al. used GPS traces to create a pedestrian navigation graph\cite{kasemsuppakorn-gps-traces-pedestrain-network}.
		Due to the inherent inaccuracies, outliers and general noise of GPS data, the traces are preprocessed to ensure a certain level of quality (for example, by only allowing points created using at least four satellites).
		The graph generation process takes one trace at a time and first determines the most significant points on that trace, which build a simplified shape of the trace.
		New segments are created and possibly merged with existing closely located segments with an almost parallel trajectory.
		
		Zhou et al. introduced another approach using crowd-sourced location data to create a navigation graph\cite{zhou-crowd-sourced-navigation}.
		They also filtered out anomalies due to inaccuracies in the GPS data and created a density map from this cleaned location data.
		The ridge lines of this density map were turned into edges since many people walked along these ridge lines.
		An evaluation of their approach showed that even small amounts of data are enough to create a sufficient routing network.
		Unsurprisingly, the accuracy and density of the network increases with the number of input trajectories.
	
\section{Routing}

	In this section, related work on general algorithms for geometric and network-based routing is presented.
	\Cref{sec:pedestrian-path-planning} contains additional specific work related to pedestrian navigation.
	
	\subsection{Geometric routing}
	\label{subsec:related-work-geometric-routing}
	
		\label{related-work:mitchell}
		Shortly after Welzl and others published their work on visibility graphs, which can be used in combination with Dijkstra to find shortest paths, Mitchell presented a purely geometric method to find Euclidean shortest paths around obstacles in the plane in 1993\cite{mitchell-shortest-path}.
		This approach is the \term*{continuous Dijkstra paradigm} and its functioning is described in \Cref{subsec:continuous-dijkstra}.
		His approach creates a shortest path map of size $\bigo{n}$ for one specific source vertex, which allows routing requests to be answered in $\bigo{\log{n}}$.
		Generating this map has a subquadratic time and space complexity of $\bigo{n^{\nicefrac{5}{3}+\epsilon}}$.
		
		Another approach to solve the geometric single-source shortest path problem was presented by Hershberger and Suri one year later, in 1997\cite{hershberger-suri}.
		They also use the \term*{continuous Dijkstra paradigm} but increase performance by introducing a special quadtree-like structure as a sophisticated subdivision of the plane and also introduce approximate wavefronts.
		The difficult part is the collision handling of non-neighboring wavelets.
		Maintaining some important properties is crucial to the efficiency when creating the subdivision, most important is the $\bigo{1}$ amount of neighboring cells around an edge.
		Their algorithm calculates a shortest path map allowing queries to be answered in only $\bigo{n \log n}$ time and space, where $n$ is the number of vertices in all obstacles.
		
		In a more recent paper, Shen et al. combined an obstacle-avoiding pathfinding algorithm with compressed path databases\cite{shen-euclidean-routing-cpd}.
		One aspect of their work, particularly important for this thesis, is the filtering of vertices used to create a visibility graph.
		They only considered the set of vertices, which are part of the convex hull of an obstacle.
		This does not yield a subquadratic time complexity but reduces the number of generated edges.
		
		A visibility graph can also be generated on a grid, which was done by Oh et al.\cite{oh-grid-vgraph}.
		They introduced two new algorithms to create sparse navigation graphs on a grid.
		Next to the convex vertex filtering, which was also used by Shen et al., they introduced the concept of so-called taut regions.
		For each vertex, these regions are determined and used to prune edges, which will never be part of any shortest path.
		This additional filtering step further increases performance by reducing the number of output edges without affecting the accuracy of shortest paths.
		Another aspect relevant to this thesis is their handling of collinear vertices.
		Instead of naively considering them as $k$ sized clique, which would result in $\bigo{k^2}$ edges for $k$ collinear vertices, they instead form one line with $k-1$ edges.
		
		Both filtering methods, convex vertices and taut regions, were implemented independent and without any prior knowledge of the two papers mentioned above.
		Details on the implementation used in this thesis are given in \Cref{chap:implementation}.
		
	\subsection{Network-based routing}
	
		The topic of network-based routing, meaning the problem of determining shortest paths in a graph, is a well-studied area with widely used algorithms.
		
		One of the most popular algorithms is the A* algorithm introduced by Hart, Nilsson and Raphael in 1968\cite{astar}.
		A detailed description of A*, including its time and space complexities, can be found in \Cref{subsubsec:astar}.

		Because the result of this thesis can be used with any network-based algorithm, all previously described \hyperref[subsec:routing-engines]{routing algorithms} and \hyperref[subsec:speedup-methods]{speedup methods} are related to this thesis.
		The combination of speedup methods is also possible and has been studied by Bauer et al.\cite{bauer-combining-speedup-methods} with promising results on the combination of arc-flags and highway hierarchies, which they called CHASE.
		A comparison by Bast et al. showed the performance increase against normal speedup methods\cite{bast-transportation-networks}, for example, contraction hierarchies had a 19 times slower query but a six times faster preprocessing time.

\section{Pedestrian pathfinding}
\label{sec:pedestrian-path-planning}
	
	A special case of the general single-source shortest path problem is pedestrian routing, also called pedestrian shortest pathfinding.
	This problem is especially interesting since pedestrians have the maximum degree of flexibility/freedom compared to other traffic participants, such as bikes or cars.
	Therefore, geometric routing is a good way to find shortest paths for pedestrians.
	
	Pedestrian pathfinding is not only relevant for real-world users who want to know how to get from one location to another.
	Such algorithms are also used in (multi) agent simulations to model pedestrian behavior accurately.
	Scenarios in such simulations are, for example, evacuations or crowd behaviors.
	The area of pedestrian path planning and simulations is divided into two strategies: network- and field-based pathfinding\cite{hartmann-geodesic}.
	Works from both strategies will be covered in the following.
	
	\subsection{Field-based and dynamic navigation}
	\label{subsec:field-based-routing}
	
		Besides geometric and network-based routing, potential fields can also be used to find shortest paths within this field.
		
		Teknomo and Millonig created a dynamic algorithm that does not pre-compute the path with one of the approaches mentioned above\cite{teknomo-millonig-routing}.
		This is interesting since the probably most common and naive approach is to pre-compute the route used by an agent within a simulation.
		The term \enquote{dynamic} refers to the fact that real-world pedestrians often only consider the near neighborhood within their path planning.
		Even if a person knows the whole area, dynamic changes (closed doors, construction work, crowds blocking the way) can still occur at any point in time.
		Therefore, considering such dynamic changes make agent-based simulations more realistic.
		
		The aforementioned dynamic routing by Teknomo and Millonig has strong similarities to approaches based on potential fields, like the dynamic pathfinding from Hartmann\cite{hartmann-geodesic}.
		He proposed a mechanism using vector fields in a cellular automaton model with hexagonal cells to find paths through open spaces.
		Interestingly, this method can be interpreted as wavefronts, like in the continuous Dijkstra paradigm, propagating through the vector field.
			
	\subsection{Graph-based path planning}
	
		An alternative to field-based approaches are graph-based ones, where a graph is constructed and then used in navigation.
		The construction can be based on potential fields but also on the \hyperref[subsec:related-work:visibility-graph]{aforementioned} \term*[visibility graph]{visibility graphs}.
		
		In fact, Gloor, Stucki and Nagel presented a pedestrian navigation model and a comparison of these two strategies regarding their performance\cite{gloor-hybrid-pedestrian-routing}.
		They developed this model for a pedestrian simulation in the Alps, where a hiking network should be enhanced with additional navigation information.
		Two approaches were presented:
		a potential field, which is used in navigation when needed, and a visibility graph, which is merged into the existing hiking network.
		For the performance evaluation, they used an evacuation scenario with the results that both navigation mechanisms are comparably fast.
		
		The work of Kneidl et al. from \Cref{subsec:filling-open-spaces} was used by Kielar et al. as a basis for a generalized routing model for pedestrian simulations\cite{kielar-unified-pedestrian-routing} taking cognitive models of agents into account.
		Cognitive models take into account that humans have their own mixed and fuzzy path-finding behavior, which differs from optimal mathematical algorithms like Dijkstra.
		The basic behaviors of human crowds are herding and learning from others, which makes communication and observation between agents necessary.